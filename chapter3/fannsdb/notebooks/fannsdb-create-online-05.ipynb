{
 "metadata": {
  "name": "",
  "signature": "sha256:572098647a656c229cec4249dc6d9e87616165279ed0bca0552a7f565e454932"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "FannsDB creation (online)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As the cluster nodes don't have internet access I need to run the online operations in a separated notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "client = Client(profile=\"nb\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dv = client[:]\n",
      "lb = client.load_balanced_view()\n",
      "lb.block = False\n",
      "lb.ordered = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "from __future__ import print_function\n",
      "\n",
      "import os\n",
      "from pymongo import MongoClient\n",
      "from ipnb.db.tasks import Task, mongodb_from_uri\n",
      "from ipnb.path import ensure_path_exists\n",
      "from ipnb.temp import temp_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from functools import partial\n",
      "from IPython.display import display, FileLink\n",
      "from ipnb.display.tasks import display_task"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "import sys\n",
      "import logging\n",
      "logger = logging.getLogger()\n",
      "for h in logger.handlers:\n",
      "    logger.removeHandler(h)\n",
      "h = logging.StreamHandler(sys.stdout)\n",
      "h.setFormatter(logging.Formatter(\"%(asctime)s %(name)-10s [%(levelname)-7s] %(message)s\", \"%Y-%m-%d %H:%M:%S\"))\n",
      "logger.addHandler(h)\n",
      "logger.setLevel(logging.INFO)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "\n",
      "SCRATCH_PATH = TMP_PATH = \"/home/cperez/temp/tmp\"\n",
      "WORK_PATH = \"/shared/projects/fannsdb/notebooks-data/fanns-perf\"\n",
      "\n",
      "CHROMOSOMES = [str(x) for x in range(1, 23)] + [\"X\", \"Y\"]\n",
      "\n",
      "# MongoDB\n",
      "\n",
      "FANNSDB_URI = \"mongodb://lima1/fanns05\"\n",
      "\n",
      "MONGODB = dict( # deprecated\n",
      "    uri=FANNSDB_URI,\n",
      "    url=\"mongodb://lima1\", db=\"fanns05\")\n",
      "\n",
      "# Ensembl\n",
      "\n",
      "ENSEMBL_64 = \"sep2011.archive.ensembl.org\"\n",
      "ENSEMBL_66 = \"feb2012.archive.ensembl.org\"\n",
      "ENSEMBL_LAST = \"www.ensembl.org\"\n",
      "ENSEMBL_HOST = ENSEMBL_64\n",
      "\n",
      "PROTEINS_PATH = os.path.join(WORK_PATH, \"proteins.list\")\n",
      "MAPS_PATH = os.path.join(WORK_PATH, \"maps\")\n",
      "ENST_PATH = os.path.join(MAPS_PATH, \"prot_transcript.tsv\")\n",
      "UNIPROT_PATH = os.path.join(MAPS_PATH, \"prot_swissprot_id.tsv\")\n",
      "\n",
      "# CADD\n",
      "\n",
      "CADD_SRC_PATH = \"/shared/datasets/CADD/whole_genome_SNVs.tsv.gz\"\n",
      "\n",
      "# CHASM\n",
      "\n",
      "CHASM_BIN_PATH = \"/shared/datasets/CHASM/CHASM3/CHASM\"\n",
      "SVNBOX_BIN_PATH = \"/shared/datasets/CHASM/CHASM3/SNVBox\"\n",
      "CHASM_PATH = WORK_PATH + \"/CHASM3\"\n",
      "\n",
      "# FATHMM cancer\n",
      "\n",
      "FATHMMC_PATH = os.path.join(WORK_PATH, \"FATHMMC_WG\")\n",
      "FATHMMC_DS_PATH = os.path.join(WORK_PATH, \"FATHMMC_DS\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Ensembl proteins"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash -s $ENSEMBL_HOST $PROTEINS_PATH\n",
      "host=$1\n",
      "file=$2\n",
      "(curl -o - --data-urlencode query@-  http://$host/biomart/martservice |\n",
      " gawk '$1 != \"\"' |\n",
      " grep -vE \"^LRG.*\" |\n",
      " sort -u >>$file) <<EOF\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<!DOCTYPE Query>\n",
      "<Query  virtualSchemaName = \"default\" formatter = \"TSV\" header = \"0\" uniqueRows = \"1\" count = \"\" datasetConfigVersion = \"0.6\" >\n",
      "    <Dataset name = \"hsapiens_gene_ensembl\" interface = \"default\" >\n",
      "        <Attribute name = \"ensembl_peptide_id\" />\n",
      "    </Dataset>\n",
      "</Query>\n",
      "EOF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\n",
        "\r",
        "  0     0    0     0    0   566      0  12160 --:--:-- --:--:-- --:--:-- 12160\r",
        "  0     0    0     0    0   566      0    540 --:--:--  0:00:01 --:--:--     0\r",
        "  0     0    0     0    0   566      0    276 --:--:--  0:00:02 --:--:--     0\r",
        "100  185k    0  185k    0   566  66865    199 --:--:--  0:00:02 --:--:-- 67773\r",
        "100  625k    0  625k    0   566   162k    147 --:--:--  0:00:03 --:--:--  164k\r",
        "100 1089k    0 1089k    0   566   225k    116 --:--:--  0:00:04 --:--:--  227k\r",
        "100 1440k    0 1440k    0   566   260k    102 --:--:--  0:00:05 --:--:--  320k\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head $PROTEINS_PATH"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ENSP00000000233\r\n",
        "ENSP00000000412\r\n",
        "ENSP00000000442\r\n",
        "ENSP00000001008\r\n",
        "ENSP00000001146\r\n",
        "ENSP00000002125\r\n",
        "ENSP00000002165\r\n",
        "ENSP00000002501\r\n",
        "ENSP00000002596\r\n",
        "ENSP00000002829\r\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Ensembl mappings"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Retrieve mappings from Ensembl protein to Ensembl transcript and from Ensembl Protein to Swissprot ID"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "maps = [\n",
      "    (\"swissprot_id\", \"Swissprot ID\", \"protein\", 10, \"prot_swissprot_id.tsv\", \"ensembl_peptide_id\", \"uniprot_swissprot\"),\n",
      "    (\"swissprot_acc\", \"Swissprot Accession\", \"protein\", 20, \"prot_swissprot_acc.tsv\", \"ensembl_peptide_id\", \"uniprot_swissprot_accession\"),\n",
      "    (\"refseq_prot\", \"Refseq Protein\", \"protein\", 30, \"prot_refseq_prot.tsv\", \"ensembl_peptide_id\", \"refseq_peptide\"),\n",
      "    (\"prot_gene\", \"Protein gene ID\", \"protein\", 40, \"prot_gene.tsv\", \"ensembl_peptide_id\", \"ensembl_gene_id\"),\n",
      "    (\"prot_transcript\", \"Protein transcript ID\", \"protein\", 50, \"prot_transcript.tsv\", \"ensembl_peptide_id\", \"ensembl_transcript_id\"),\n",
      "    (\"gene\", \"Ensembl Gene\", \"transcript\", None, \"trans_gene.tsv\", \"ensembl_transcript_id\", \"ensembl_gene_id\"),\n",
      "    (\"symbol\", \"HGNC Symbol\", \"transcript\", None, \"trans_sym.tsv\", \"ensembl_transcript_id\", \"hgnc_symbol\"),\n",
      "    (\"entrez\", \"Entrez Gene\", \"transcript\", None, \"trans_entrez.tsv\", \"ensembl_transcript_id\", \"entrezgene\"),\n",
      "    (\"omim_gene\", \"OMIM Gene\", \"transcript\", None, \"trans_mim_gene_acc.tsv\", \"ensembl_transcript_id\", \"mim_gene_accession\"),\n",
      "    (\"omim_gene_desc\", \"OMIM Gene Description\", \"transcript\", None, \"trans_mim_gene_desc.tsv\", \"ensembl_transcript_id\", \"mim_gene_description\"),\n",
      "    (\"omim_morbid\", \"OMIM Morbid\", \"transcript\", None, \"trans_mim_morbid_acc.tsv\", \"ensembl_transcript_id\", \"mim_morbid_accession\"),\n",
      "    (\"omim_morbid_desc\", \"OMIM Morbid Description\", \"transcript\", None, \"trans_mim_morbid_desc.tsv\", \"ensembl_transcript_id\", \"mim_morbid_description\")\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def download_mapping(params, host, base_path, temp_prefix=None, overwrite=False):\n",
      "    _, _, _, _, filename, src, dst = params\n",
      "    path = os.path.join(base_path, filename)\n",
      "    \n",
      "    import tempfile\n",
      "    if os.path.exists(path) and not overwrite:\n",
      "        return path\n",
      "    \n",
      "    tmp_path = temp_file(temp_prefix).name\n",
      "    !ensembl-get-ann $host $tmp_path $src $dst 2>/dev/null\n",
      "    !mv $tmp_path $path\n",
      "    \n",
      "    return path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not MAPS_PATH:\n",
      "    os.makedirs(MAPS_PATH)\n",
      "\n",
      "fn = partial(download_mapping, host=ENSEMBL_HOST, base_path=base_path)\n",
      "dn_maps_ar = lb.map(fn, maps)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display_task(client, dn_maps_ar)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dn_maps_ar.wait()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head $ENST_PATH"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# 03/08/14 08:19:13\r\n",
        "## host=sep2011.archive.ensembl.org\r\n",
        "## attr_src=ensembl_peptide_id\r\n",
        "## attr_dst=ensembl_transcript_id\r\n",
        "ENSP00000000233\tENST00000000233\r\n",
        "ENSP00000000412\tENST00000000412\r\n",
        "ENSP00000000442\tENST00000000442\r\n",
        "ENSP00000001008\tENST00000001008\r\n",
        "ENSP00000001146\tENST00000001146\r\n",
        "ENSP00000002125\tENST00000002125\r\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import mappings into the MongoDB"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from fannsdb import FannsMongoDb\n",
      "from fannsdb.ops.maps import add_map\n",
      "from datetime import datetime as dt\n",
      "\n",
      "db = FannsMongoDb(MONGODB[\"url\"], db=MONGODB[\"db\"])\n",
      "for map_id, map_name, map_type, prio, filename, _, _ in maps:\n",
      "    path = os.path.join(MAPS_PATH, filename)\n",
      "    print(\"{} Importing {} ...\".format(dt.now(), map_name))\n",
      "    add_map(db, map_id, map_name, map_type, prio or 0, path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-03-08 09:30:22.548378 Importing Swissprot ID ...\n",
        "2014-03-08 09:31:09.937672 Importing Swissprot Accession ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-03-08 09:31:57.649931 Importing Refseq Protein ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-03-08 09:33:34.370934 Importing Protein gene ID ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-03-08 09:36:22.941210 Importing Protein transcript ID ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-03-08 09:39:10.860026 Importing Ensembl Gene ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-03-08 09:45:16.878143 Importing HGNC Symbol ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-03-08 09:50:18.519231 Importing Entrez Gene ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-03-08 09:54:30.515946 Importing OMIM Gene ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-03-08 09:57:39.163446 Importing OMIM Gene Description ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-03-08 10:00:50.059383 Importing OMIM Morbid ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-03-08 10:02:02.085716 Importing OMIM Morbid Description ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**The following code should be removed and the code using the ensp_xrefs collection be replaced to use FannsDb interface**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bgcore import tsv\n",
      "from pymongo import MongoClient\n",
      "\n",
      "with MongoClient(MONGODB[\"url\"]) as conn:\n",
      "    db = conn[MONGODB[\"db\"]]\n",
      "    ensp_xrefs = db.ensp_xrefs\n",
      "    \n",
      "    print(\"Importing ensp <-> enst ...\")\n",
      "    with tsv.open(ENST_PATH) as f:\n",
      "        for ensp, enst in tsv.rows(f):\n",
      "             ensp_xrefs.update({\"_id\" : ensp}, {\"$addToSet\" : {\"enst\" : enst}}, upsert=True)\n",
      "    \n",
      "    print(\"Importing ensp <-> swissprot_id ...\")\n",
      "    with tsv.open(UNIPROT_PATH) as f:\n",
      "        for ensp, swissprot_id in tsv.rows(f):\n",
      "             ensp_xrefs.update({\"_id\" : ensp}, {\"$addToSet\" : {\"swissprot_id\" : swissprot_id}}, upsert=True)\n",
      "    \n",
      "    print(\"Creating indices ...\")\n",
      "    ensp_xrefs.ensure_index([(\"enst\", 1)])\n",
      "    ensp_xrefs.ensure_index([(\"swissprot_id\", 1)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Importing ensp <-> enst ...\n",
        "Importing ensp <-> swissprot_id ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Creating indices ..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exome regions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Download all the exome chromosome regions from the Ensembl Biomart"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def download_exome_regions(chrom, host, path, temp_prefix=None, overwrite=False):\n",
      "    import tempfile\n",
      "    import requests as rq\n",
      "    \n",
      "    out_path = os.path.join(path, \"exons-{}.tsv\".format(chrom))\n",
      "    if os.path.exists(out_path) and not overwrite:\n",
      "        return out_path\n",
      "    \n",
      "    url = \"http://{}/biomart/martservice\".format(host)\n",
      "    query = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?><!DOCTYPE Query>\n",
      "    <Query virtualSchemaName=\"default\" formatter=\"TSV\" header=\"0\" uniqueRows=\"1\" count=\"\" datasetConfigVersion=\"0.6\">\n",
      "        <Dataset name=\"hsapiens_gene_ensembl\" interface=\"default\">\n",
      "            <Filter name=\"chromosome_name\" value=\"{}\"/>\n",
      "            <Attribute name=\"chromosome_name\" />\n",
      "            <Attribute name=\"exon_chrom_start\" />\n",
      "            <Attribute name=\"exon_chrom_end\" />\n",
      "            <Attribute name=\"ensembl_exon_id\" />\n",
      "        </Dataset>\n",
      "    </Query>\"\"\".format(chrom)\n",
      "    r = rq.post(url, data={\"query\" : query}, stream=True)\n",
      "    \n",
      "    tmp_path = tempfile.NamedTemporaryFile(prefix=temp_prefix).name\n",
      "    with open(tmp_path, 'wb') as fd:\n",
      "        for chunk in r.iter_content(4*1024*1024):\n",
      "            fd.write(chunk)\n",
      "    \n",
      "    !cat $tmp_path | gawk '$1 != \"\" && $2 != \"\" && $3 != \"\" && $4 != \"\"' | sort -t $'\\t' -u -k2n,2 -k3n,3 >$out_path\n",
      "    \n",
      "    return out_path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = os.path.join(WORK_PATH, \"exons\")\n",
      "if not os.path.exists(path):\n",
      "    os.makedirs(path)\n",
      "\n",
      "fn = partial(download_exome_regions, host=ENSEMBL_HOST, path=path, temp_prefix=SCRATCH_PATH)\n",
      "exome_amr = lb.map(fn, CHROMOSOMES)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for r in exome_amr:\n",
      "    print(os.path.relpath(r, WORK_PATH))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "exons/exons-1.tsv\n",
        "exons/exons-2.tsv\n",
        "exons/exons-3.tsv\n",
        "exons/exons-4.tsv\n",
        "exons/exons-5.tsv\n",
        "exons/exons-6.tsv\n",
        "exons/exons-7.tsv\n",
        "exons/exons-8.tsv\n",
        "exons/exons-9.tsv\n",
        "exons/exons-10.tsv\n",
        "exons/exons-11.tsv\n",
        "exons/exons-12.tsv\n",
        "exons/exons-13.tsv\n",
        "exons/exons-14.tsv\n",
        "exons/exons-15.tsv\n",
        "exons/exons-16.tsv\n",
        "exons/exons-17.tsv\n",
        "exons/exons-18.tsv\n",
        "exons/exons-19.tsv\n",
        "exons/exons-20.tsv\n",
        "exons/exons-21.tsv\n",
        "exons/exons-22.tsv\n",
        "exons/exons-X.tsv\n",
        "exons/exons-Y.tsv\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "dbNSFP"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get the database zip from https://sites.google.com/site/jpopgen/dbNSFP. I used version 2.1. It is already downloaded at */shared/datasets/dbNSFP*."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "CADD"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I get all possible SNVs file from http://cadd.gs.washington.edu/download. It is already downloaded at */shared/datasets/CADD*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The provided tabix file didn't work so I had to reindex the file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!tabix -f -s 1 -b 2 -e 2 $CADD_SRC_PATH"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!zcat $CADD_SRC_PATH | head"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "## (c) University of Washington and Hudson-Alpha Institute for Biotechnology 2013. All rights reserved.\r\n",
        "#Chrom\tPos\tRef\tAlt\tRawScore\tPHRED\r\n",
        "1\t10001\tT\tA\t-0.527445\t1.597\r\n",
        "1\t10001\tT\tC\t-0.642756\t1.165\r\n",
        "1\t10001\tT\tG\t-0.636787\t1.186\r\n",
        "1\t10002\tA\tC\t-0.641259\t1.170\r\n",
        "1\t10002\tA\tG\t-0.647307\t1.149\r\n",
        "1\t10002\tA\tT\t-0.533326\t1.574\r\n",
        "1\t10003\tA\tC\t-0.635400\t1.191\r\n",
        "1\t10003\tA\tG\t-0.641448\t1.169\r\n",
        "\r\n",
        "gzip: stdout: Broken pipe\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "CHASM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First of all CHASM has to be downloaded and installed."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    !axel http://karchinlab.org/chasmdl/SNVBox.2.0.0.sql.gz\n",
      "    \n",
      "    !mysql -h kabul -u cperez -p CHASM < ..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calculation will be parallelized by protein:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logger.info(\"Loading proteins ...\")\n",
      "proteins = set()\n",
      "with open(PROTEINS_PATH) as f:\n",
      "    for line in f:\n",
      "        proteins.add(line.rstrip(\"\\n\"))\n",
      "logger.info(\"  {} proteins\".format(len(proteins)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-04-15 08:19:59 root       [INFO   ] Loading proteins ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-04-15 08:19:59 root       [INFO   ]   92012 proteins\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we will generate the CHASM input files with the SNVs available in the database."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ensure_path_exists(CHASM_PATH)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def chasm_prepare_input(protein, out_base_path, db_uri):\n",
      "    \n",
      "    with Task(db_uri, \"chasm-input\", protein) as task:\n",
      "    \n",
      "        db = mongodb_from_uri(db_uri)\n",
      "        db.connection.write_concern.update(dict(j=False))\n",
      "\n",
      "        out_path = os.path.join(out_base_path, \"{}.tsv\".format(protein))\n",
      "\n",
      "        snvs = set()\n",
      "        for snv in db.scores.find({\"p.n\" : protein}):\n",
      "            p = snv[\"p\"]\n",
      "            snvs.add((protein, p[\"p\"], p[\"r\"], p[\"a\"]))\n",
      "\n",
      "        if len(snvs) > 0:\n",
      "            with open(out_path, \"w\") as f:\n",
      "                for protein, pos, ref, alt in sorted(snvs):\n",
      "                    f.write(\"{}\\t{}{}{}\\n\".format(protein, ref, pos, alt))\n",
      "        \n",
      "        task.metadata(num_snvs=len(snvs))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fn = partial(chasm_prepare_input, out_base_path=CHASM_PATH, db_uri=FANNSDB_URI)\n",
      "cpi_amr = lb.map_async(fn, sorted(proteins))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cpi_amr.r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calculate CHASM for all the prepared proteins"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def chasm_run(path, chasm_bin_path, svnbox_bin_path, db_uri):\n",
      "    from subprocess import call\n",
      "    \n",
      "    dirname = os.path.dirname(path)\n",
      "    protein = os.path.basename(path)[:-4]\n",
      "    with Task(db_uri, \"chasm-run\", protein) as task:\n",
      "        task.logger.info(\"Running CHASM for protein {} ...\".format(protein))\n",
      "        \n",
      "        # Run CHASM\n",
      "        os.chdir(chasm_bin_path)\n",
      "        log_path = os.path.join(dirname, protein + \".log\")\n",
      "        with open(log_path, \"w\") as f:\n",
      "            env = dict(\n",
      "                CHASMDIR=chasm_bin_path,\n",
      "                SNVBOXDIR=svnbox_bin_path)\n",
      "            code = call(\"./RunChasm OV {}\".format(path), stdout=f, stderr=f, env=env, shell=True)\n",
      "        if code != 0:\n",
      "            task.logger.error(\"Failed to run CHASM with protein {}\".format(protein))\n",
      "            with open(log_path) as f:\n",
      "                task.logger.error(f.read())\n",
      "        \n",
      "        in_count = !cat $path | wc -l\n",
      "        out_path = os.path.join(dirname, protein + \"OV.output\")\n",
      "        out_count = !cat $out_path | wc -l\n",
      "        os.remove(os.path.join(dirname, protein + \".arff\"))\n",
      "        os.remove(os.path.join(dirname, protein + \".classified\"))\n",
      "        os.rename(out_path, os.path.join(dirname, protein + \".output\"))\n",
      "        \n",
      "        in_count = int(in_count[0])\n",
      "        out_count = int(out_count[0])\n",
      "        lost_count = in_count - out_count\n",
      "        \n",
      "        task.logger.info(\"Done: in={}, out={}, lost={}\".format(in_count, out_count, lost_count))\n",
      "        task.metadata(in_muts=in_count, out_muts=out_count, lost_muts=lost_count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "paths = [os.path.join(CHASM_PATH, fname) for fname in os.listdir(CHASM_PATH) if fname.endswith(\".tsv\")]\n",
      "fn = partial(chasm_run, chasm_bin_path=CHASM_BIN_PATH, svnbox_bin_path=SVNBOX_BIN_PATH, db_uri=FANNSDB_URI)\n",
      "cr_amr = lb.map_async(fn, sorted(paths))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cr_amr.progress"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 126,
       "text": [
        "77579"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"\\n\".join(cr_amr.stdout))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "FATHMM for cancer"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Download the FATHMM database and the python script\n",
      "* Import the database into a mysql server\n",
      "* Execute the script for all the proteins in the database"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Import the scores into MongoDB"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**TODO** the following code still uses the deprecated way to open the database using MONGODB instead of FANNSDB_URI (see the following cell defining *fathmmc_updatedb_from_file* as reference)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def fathmmc_updatedb(protein_path, db_conf):\n",
      "    import gzip\n",
      "    from datetime import datetime as dt\n",
      "    from pymongo import MongoClient\n",
      "    \n",
      "    print(\"{} Importing protein {} ...\".format(dt.now(), os.path.basename(protein_path).replace(\".fathmm.gz\", \"\")))\n",
      "    \n",
      "    i = 0\n",
      "    with MongoClient(MONGODB[\"url\"]) as conn, gzip.open(protein_path) as f:\n",
      "        db = conn[MONGODB[\"db\"]]\n",
      "        scores = db.scores\n",
      "        \n",
      "        db.tasks.update({\"name\" : \"fathmmc\", \"item\" : protein_path},\n",
      "                        {\"$set\" : {\"state\" : \"started\", \"started\" : dt.now()}}, upsert=True)\n",
      "        \n",
      "        updated = skipped = 0\n",
      "        f.readline() # skip header\n",
      "        for i, line in enumerate(f, start=1):\n",
      "            fields = line.rstrip(\"\\n\").split(\"\\t\")\n",
      "            try:\n",
      "                protein, subst, score = [fields[j] for j in [2, 3, 5]]\n",
      "                apos, aref, aalt = int(subst[1:-1]), subst[0], subst[-1]\n",
      "                score = float(score)\n",
      "            except:\n",
      "                skipped += 1\n",
      "                continue\n",
      "            \n",
      "            scores.update({\"p.n\" : protein, \"p.p\" : apos, \"p.r\" : aref, \"p.a\" : aalt},\n",
      "                          {\"$set\" : {\"s.FATHMMC\" : score}},\n",
      "                          multi=True, w=1 if i % 1000 == 0 else 0)\n",
      "            updated += 1\n",
      "    \n",
      "    db.tasks.update({\"name\" : \"fathmmc\", \"item\" : protein_path},\n",
      "                        {\"$set\" : {\"state\" : \"finished\", \"finished\" : dt.now(),\n",
      "                                   \"meta.updated_rows\" : updated,\n",
      "                                   \"meta.skipped_rows\" : skipped,\n",
      "                                   \"meta.total_rows\" : i}})\n",
      "    \n",
      "    print(\"{} Total {} rows imported, {} rows skipped\".format(dt.now(), updated, skipped))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "fn = partial(fathmmc_updatedb, db_conf=MONGODB)\n",
      "files = glob.glob(os.path.join(FATHMMC_PATH, \"*.fathmm.gz\"))\n",
      "fathmmc_updatedb_amr = lb.map(fn, files)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display_task(client, fathmmc_updatedb_amr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For updates from a file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px --local\n",
      "def fathmmc_updatedb_from_file(path, db_uri):\n",
      "    import gzip\n",
      "    from ipnb.db.tasks import Task, mongodb_from_uri\n",
      "    \n",
      "    with Task(db_uri, \"fathmmc-file\", os.path.basename(path)) as task:\n",
      "        \n",
      "        basename = os.path.basename(path).replace(\".fathmm.gz\", \"\")\n",
      "        \n",
      "        task.logger.info(\"Importing {} ...\".format(basename))\n",
      "    \n",
      "        db = mongodb_from_uri(db_uri)\n",
      "        scores = db.scores\n",
      "        \n",
      "        with gzip.open(path) as f:\n",
      "            updated = skipped = 0\n",
      "            #f.readline() # skip header\n",
      "            i = 0\n",
      "            for i, line in enumerate(f, start=1):\n",
      "                fields = line.rstrip(\"\\n\").split(\"\\t\")\n",
      "                try:\n",
      "                    protein, subst, score = [fields[j] for j in [2, 3, 5]]\n",
      "                    apos, aref, aalt = int(subst[1:-1]), subst[0], subst[-1]\n",
      "                    score = float(score)\n",
      "                except:\n",
      "                    skipped += 1\n",
      "                    continue\n",
      "\n",
      "                scores.update({\"p.n\" : protein, \"p.p\" : apos, \"p.r\" : aref, \"p.a\" : aalt},\n",
      "                              {\"$set\" : {\"s.FATHMMC\" : score}},\n",
      "                              multi=True, w=1 if i % 1000 == 0 else 0)\n",
      "                \n",
      "                updated += 1\n",
      "                \n",
      "                if i % 1000 == 0:\n",
      "                    task.progress(i, \"{} rows read, {} rows updated, {} rows skipped\".format(i, updated, skipped))\n",
      "\n",
      "        task.metadata(updated_rows=updated, skipped_rows=skipped, total_rows=i)\n",
      "    \n",
      "        task.logger.info(\"Total {} rows imported, {} rows skipped\".format(updated, skipped))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fathmmc_updatedb_from_file(os.path.join(FATHMMC_DS_PATH, \"fathmmc.tsv.gz\"), FANNSDB_URI)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-05-06 17:43:40 root [INFO   ] Task fathmmc-file/fathmmc.tsv.gz started on host sydney.imim.es\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-05-06 17:43:40 root [INFO   ] Importing fathmmc.tsv.gz ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-05-06 18:00:07 root [INFO   ] Total 716671 rows imported, 62218 rows skipped\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fathmmc_updatedb_from_file(os.path.join(FATHMMC_DS_PATH, \"humvar-fathmmc.tsv.gz\"), FANNSDB_URI)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-05-06 18:34:00 root [INFO   ] Task fathmmc-file/humvar-fathmmc.tsv.gz started on host sydney.imim.es\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-05-06 18:34:00 root [INFO   ] Importing humvar-fathmmc.tsv.gz ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-05-06 18:34:05 root [INFO   ] Total 19303 rows imported, 287 rows skipped\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fathmmc_updatedb_from_file(os.path.join(WORK_PATH, \"cosmic-snvs-fix-fathmmc.tsv.gz\"), FANNSDB_URI)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-06-19 17:52:46 root [INFO   ] Task fathmmc-file/cosmic-snvs-fix-fathmmc.tsv.gz started on host sydney.imim.es\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-06-19 17:52:46 root [INFO   ] Importing cosmic-snvs-fix-fathmmc.tsv.gz ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-06-19 18:32:28 root [INFO   ] Total 348443 rows imported, 25902 rows skipped\n"
       ]
      }
     ],
     "prompt_number": 11
    }
   ],
   "metadata": {}
  }
 ]
}